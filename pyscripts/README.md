# PyScripts
Various python scripts to dump data.

## Maven packaging analysis

The [packaging_analysis.py](packaging/packaging_analysis.py) contains the python scripts to convert the raw information from the database into meaningful data.
The data can be generated by simply running the python scripts.

### Prerequisites

- Python version 3.9 or above
- The connection to the database must be established as the scripts query the database.

### Methodology

After running the python scripts, all the data is stored into text files. for all the research questions.
To generate graphs, the data from each text file should be copied to the _Analysis.xlsx_ file. This file can be found in
the [dataset](https://doi.org/10.5281/zenodo.8077125). Make sure to copy the data starting from cell _A2_ in each sheet. This will automatically
update the other columns in the spreadsheet and also generate the graphs. For the sizeplots this [dataset](https://doi.org/10.5281/zenodo.8085786) is 
used instead. 



## [Sizeplots](vc/sizeplots.py)
To obtain the desired graphs for the size and dependency extractor, run this file. 
Make sure to change the Database variables to their corresponding values (name, port, username, password)
and change the SQL statement to match your table name (default is packages).

Running the sizeplots will yield 4 graphs. The first one displays the size distribution
of packages in the ecosystem. Make sure to save it if desired, when you close the image, the next
graph shows up which is a scatterplot between the number of files and size in an artifact.
Thereafter, the same graphs for direct and transitive dependencies will be shown.

You might have to tweak the number of bins or the x-limit for the first graph 'plot_size_distribution(size)' depending
on your sample size.

## SQL queries used for excel graphs of size and dependency extractors
Not all graphs were made with python. The other graphs were made by running the following SQL queries 
on the database after which the results were inserted into excel to make a graph there.
The excel files can be found in the [resources](../analyzer/src/main/resources) directory. Size-analysis.xlsx contains
the graphs for average size of an artifact per year, 20 largest file extensions and 20
most common file extensions. Distribution.xlsx contains the distribution graphs of packages
released per year for the Maven Central index and for our sample.

Obtain the distribution of packages selected per year:

~~~postgresql
SELECT extract(year from lastmodified) as year, count(*) as count_per_year
FROM selected_packages
GROUP BY year
ORDER BY year;
~~~

Obtain the average size of an artifact per year the artifact was last modified:

~~~postgresql
SELECT EXTRACT(YEAR FROM t1.lastmodified) AS year, AVG(t2.size /1000) AS average_size
FROM package_list AS t1
         JOIN packages AS t2 ON t1.groupid = t2.groupid AND t1.artifactid = t2.artifactid AND t1.version = t2.version
GROUP BY year
ORDER BY year;
~~~

Get the 20 file extensions with the largest average size:

~~~postgresql
SELECT extension, avg((size / 1000) / extensions.count) AS mean_size
FROM extensions
GROUP BY extension
ORDER BY mean_size DESC
LIMIT 20;
~~~

Total number of occurrences for top 20 file extensions:
~~~postgresql
SELECT extension, sum(count) as occ
FROM extensions
GROUP BY extension
order by occ DESC
LIMIT 20;
~~~

## Artifacts used for manual analysis:
The following artifacts were used for conducting manual analysis of outliers in 
space requirements. These files are larger than 600MB and have less than 200 files.
- (com.facebook.presto,testdata-tpch-1g,1)
- (com.nvidia,xgboost4j_3.0,1.2.0-0.1.0)
- (com.xtdb,xtdb-bench,1.23.0)
- (fi.seco,lexicalanalysis-resources-fi,1.5.13)
- (fi.seco,lexicalanalysis-resources-fi-complete,1.5.14)
- (fi.seco,lexicalanalysis,1.5.0)
- (net.hydromatic,flight-data-hsqldb,0.2)
- (net.sourceforge.ctakesresources,ctakes-resources-lvg2008,3.1.1)
- (org.clulab,processors-models_2.12,0.0.1)
- (org.eurekaclinical,eurekaclinical-ontology,2.0.1)